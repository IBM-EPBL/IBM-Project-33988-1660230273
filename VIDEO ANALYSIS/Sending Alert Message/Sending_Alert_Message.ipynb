{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qbc8GH8_Qn5q"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing The ImageDataGenerator Library"
      ],
      "metadata": {
        "id": "r81nAQCNQpJV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "aAVV9okzQqsR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the parameters/arguments for ImageDataGenerator class"
      ],
      "metadata": {
        "id": "np-OpkkAQwXA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen=ImageDataGenerator(rescale=1./255,shear_range=0.2,\n",
        "rotation_range=180,zoom_range=0.2, horizontal_flip=True)\n",
        "test_datagen=ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "lNKtLlp_Q1cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying ImageDataGenerator functionality to trainset\n"
      ],
      "metadata": {
        "id": "-UMgMdM2Q5da"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=train_datagen.flow_from_directory(r'/content/drive/MyDrive/Dataset/train_set',\n",
        "target_size=(128,128),batch_size=32, class_mode='binary')\n",
        "Found 436 images belonging to 2 classes."
      ],
      "metadata": {
        "id": "yqrdbAnOQ8hQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying ImageDataGenerator functionality to testset"
      ],
      "metadata": {
        "id": "2dNQ0GKMRCLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_test=test_datagen.flow_from_directory(r'/content/drive/MyDrive/Dataset/test_set',\n",
        "target_size=(128,128),batch_size=32, class_mode='binary')\n",
        "Found 121 images belonging to 2 classes."
      ],
      "metadata": {
        "id": "7xCDO-i8RGTe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import model building libraries"
      ],
      "metadata": {
        "id": "cVg6Vpd5RJtF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To define Linear initialisation import Sequential\n",
        "from keras.models import Sequential\n",
        "#To add layers import Dense\n",
        "from keras.layers import Dense\n",
        "#To create Convolution kernel import Convolution2D\n",
        "from keras.layers import Convolution2D\n",
        "#import Maxpooling layer\n",
        "from keras.layers import MaxPooling2D\n",
        "#import flatten layer\n",
        "from keras.layers import Flatten import\n",
        "warnings warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "weRLvoDVRM_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initializing the model"
      ],
      "metadata": {
        "id": "iuMupNz1RQ1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()"
      ],
      "metadata": {
        "id": "yHXjspmqRT09"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add CNN Layer"
      ],
      "metadata": {
        "id": "aQCcTXWpRW76"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Convolution2D(32, (3,3),input_shape=(128,128,3),activation='relu'))\n",
        "#add maxpooling layer\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#add flatten layer\n",
        "model.add(Flatten())"
      ],
      "metadata": {
        "id": "WVZqNK90Rxl-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add Dense Layer"
      ],
      "metadata": {
        "id": "1_B-qFsmST8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#add hidden layer\n",
        "model.add(Dense(150,activation='relu'))\n",
        "#add output layer\n",
        "model.add(Dense(1,activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "TlnyEizZSVLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Configure the learning process"
      ],
      "metadata": {
        "id": "S6zfFgzBSYe8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy',optimizer=\"adam\",metrics=[\"accuracy\"])"
      ],
      "metadata": {
        "id": "KKNkfvRTSbhB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model "
      ],
      "metadata": {
        "id": "TI65QLO9SecL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(x_train,steps_per_epoch=14,epochs=10,validation_da\n",
        "ta=x_test,validation_steps=4)\n",
        "Epoch 1/10\n",
        "14/14 [==============================] - 205s 15s/step - loss: 2.7344 -\n",
        "accuracy: 0.7454 - val_loss: 0.2016 - val_accuracy: 0.9256\n",
        "Epoch 2/10\n",
        "14/14 [==============================] - 20s 1s/step - loss: accuracy: 0.8945 -\n",
        "val_loss: 0.2290 - val_accuracy: 0.9339\n",
        "Epoch 3/10\n",
        "14/14 [==============================] - 20s 1s/step - loss: accuracy: 0.8922 -\n",
        "val_loss: 0.0524 - val_accuracy: 0.9835\n",
        "Epoch 4/10\n",
        "14/14 [==============================] - 20s 1s/step - loss: accuracy: 0.9174 -\n",
        "val_loss: 0.1570 - val_accuracy: 0.9421\n",
        "Epoch 5/10\n",
        "14/14 [==============================] - 20s 1s/step - loss: accuracy: 0.9083 -\n",
        "val_loss: 0.0767 - val_accuracy: 0.9752\n",
        "Epoch 6/10\n",
        "14/14 [==============================] - 20s 1s/step - loss: accuracy: 0.9335 -\n",
        "val_loss: 0.0749 - val_accuracy: 0.9752\n",
        "Epoch 7/10\n",
        "14/14 [==============================] - 20s 1s/step - loss: accuracy: 0.9312 -\n",
        "val_loss: 0.1264 - val_accuracy: 0.9421\n",
        "Epoch 8/10\n",
        "14/14 [==============================] - 20s 1s/step - loss: accuracy: 0.9266 -\n",
        "val_loss: 0.0652 - val_accuracy: 0.9835\n",
        "Epoch 9/10\n",
        "14/14 [==============================] - 20s 1s/step - loss: accuracy: 0.9358 -\n",
        "val_loss: 0.0567 - val_accuracy: 0.9835\n",
        "Epoch 10/10\n",
        "14/14 [==============================] - 20s 1s/step - loss: accuracy: 0.9404 -\n",
        "val_loss: 0.0448 - val_accuracy: 0.9917\n",
        "0.3267 -\n",
        "0.2991 -\n",
        "0.2418 -\n",
        "0.1984 -\n",
        "0.1643 -\n",
        "0.1538 -\n",
        "0.1732 -\n",
        "0.1514 -\n",
        "0.1445 -\n",
        "<keras.callbacks.History at 0x7f51fdf33610>"
      ],
      "metadata": {
        "id": "zPBLQJcMShXB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save The Model"
      ],
      "metadata": {
        "id": "RqXHRfZXSnJx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"forest1.h5\")\n"
      ],
      "metadata": {
        "id": "nIydQNhJSqQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predictions "
      ],
      "metadata": {
        "id": "UXVdriAzStGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import load_model from keras.model\n",
        "from keras.models import load_model\n",
        "#import image class from keras\n",
        "from tensorflow.keras.preprocessing import image #import numpy import numpy as\n",
        "np\n",
        "#import cv2\n",
        "import cv2\n",
        "#load the saved model\n",
        "model = load_model(\"forest1.h5\")\n",
        "img=image.load_img(r'/content/drive/MyDrive/Dataset/test_set/forest/\n",
        "0.48007200_1530881924_final_forest.jpg')\n",
        "x=image.img_to_array(img)\n",
        "res = cv2.resize(x, dsize=(128, 128), interpolation=cv2.INTER_CUBIC) #expand the\n",
        "image shape\n",
        "x=np.expand_dims(res,axis=0)\n",
        "pred= model.predict(x)\n",
        "1/1 [==============================] - 0s 94ms/step pred\n",
        "array([[0.]], dtype=float32)"
      ],
      "metadata": {
        "id": "cfzHIsDfSvs9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenCV For Video Processing"
      ],
      "metadata": {
        "id": "DX26ZvgUS0wt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "pip install twilio\n",
        "Looking in indexes: https://pypi.org/simple, https://uspython.pkg.dev/colab-wheels/public/simple/\n",
        "Collecting twilio\n",
        "Downloading twilio-7.15.1-py2.py3-none-any.whl (1.4 MB)\n",
        "ent already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from twilio)\n",
        "(2022.5)\n",
        "Collecting PyJWT<3.0.0,>=2.0.0\n",
        "Downloading PyJWT-2.6.0-py3-none-any.whl (20 kB)\n",
        "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.7/distpackages (from twilio) (2.23.0) Requirement already satisfied: chardet<4,>=3.0.2 in\n",
        "/usr/local/lib/python3.7/dist-packages (from requests>=2.0.0->twilio) (3.0.4)\n",
        "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages\n",
        "(from requests>=2.0.0->twilio)\n",
        "(2.10)\n",
        "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-\n",
        "packages (from requests>=2.0.0->twilio) (2022.9.24)\n",
        "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in\n",
        "/usr/local/lib/python3.7/dist-packages (from requests>=2.0.0- >twilio) (1.24.3)\n",
        "Installing collected packages: PyJWT, twilio\n",
        "Successfully installed PyJWT-2.6.0 twilio-7.15.1\n",
        "pip install playsound\n",
        "Looking in indexes: https://pypi.org/simple, https://uspython.pkg.dev/colab-wheels/public/simple/\n",
        "Collecting playsound\n",
        "Downloading playsound-1.3.0.tar.gz (7.7 kB) Building wheels for collected\n",
        "packages: playsound\n",
        "Building wheel for playsound (setup.py) ... e=playsound-1.3.0-py3- none-any.whl\n",
        "size=7035\n",
        "sha256=e7e96c774a98522e182b59b7b292f0f932097658d8bfce86c922c363f862b0e\n",
        "2\n",
        "Stored in directory:\n",
        "/root/.cache/pip/wheels/ba/f8/bb/ea57c0146b664dca3a0ada4199b0ecb5f9dfc\n",
        "b7b7e22b65ba2\n",
        "Successfully built playsound\n",
        "Installing collected packages: playsound\n",
        "Successfully installed playsound-1.3.0 "
      ],
      "metadata": {
        "id": "sy5toRaoS4uC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import opencv library\n",
        "import cv2\n",
        "#import numpy\n",
        "import numpy as np\n",
        "#import image function from keras\n",
        "from keras.preprocessing import image\n",
        "#import load_model from keras\n",
        "from keras.models import load_model\n",
        "#import client from twilio API\n",
        "from twilio.rest import Client\n",
        "#import playsound package\n",
        "from playsound import playsound "
      ],
      "metadata": {
        "id": "GWrjT88cTAaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "WARNING:playsound:playsound is relying on another python subprocess. Please\n",
        "use `pip install pygobject` if you want playsound to run more efficiently.\n"
      ],
      "metadata": {
        "id": "Xovh0nX3TLOV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load the saved model\n",
        "model=load_model(\"forest1.h5\") #define video video=cv2.VideoCapture(0) #define\n",
        "the features name=['forest','with fire'] "
      ],
      "metadata": {
        "id": "9hEzqc4HTOs3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating An Account In Twilio Service"
      ],
      "metadata": {
        "id": "VISUCnJpTVXE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "account_sid='ACfb4e6d0e7b0d25def63044919f1b96e3'\n",
        "auth_token='f9ae4fc4a617a527da8672e97eefb2d8'\n",
        "client=Client(account_sid,auth_token)\n",
        "message=client.messages \\\n",
        ".create(\n",
        " body='Forest Fire is detected, stay alert',\n",
        " from_='+1 302 248 4366',\n",
        " to='+91 99400 12164'\n",
        ")\n",
        "print(message.sid)\n",
        "SM4aa5a4751b7bcec159dc4c695752293d\n"
      ],
      "metadata": {
        "id": "6quqGM58TWT7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sending Alert Message"
      ],
      "metadata": {
        "id": "kFYOXBG6TdZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while(1):\n",
        "sucess, frame= video.read()\n",
        "cv2.imwrite(\"image.jpg\",frame)\n",
        "img=image.load_img(\"image.jpg\",target_size=(64,64)) x=image.img_to_array(img)\n",
        "x=np.expand_dims(x,axis=0)\n",
        "pred=model.predict_classes(x)\n",
        "p=pred[0]\n",
        "print(pred)\n",
        "cv2.putText(frame,\"predicted class=\"+str(name[p]),(100,100),\n",
        "cv2.FONT_HERSHEY_SIMPLEX,1, (0,0,0), 1) pred = model.predict_classes(x) if\n",
        "pred[0]==1:\n",
        "account_sid='ACfb4e6d0e7b0d25def63044919f1b96e3'\n",
        "auth_token='f9ae4fc4a617a527da8672e97eefb2d8'\n",
        "client=Client(account_sid,auth_token) message=client.messages \\\n",
        ".create(\n",
        "body='Forest Fire is detected, stay alert', from_='+1 302 248 4366',\n",
        "to='+91 99400 12164'\n",
        ")\n",
        "print(message.sid) print('Fire Detected') print('SMS sent!')\n",
        "else:\n",
        "print('No Danger') cv2.imshow(\"image\",frame)\n",
        "if cv2.waitkey(1) & 0xFF == ord('a'): break\n",
        "video.release() cv2.destryoAllWindows() "
      ],
      "metadata": {
        "id": "KXHAs8dpTgit"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}